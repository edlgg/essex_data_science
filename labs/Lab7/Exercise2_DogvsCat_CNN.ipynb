{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Exercise2_DogvsCat_CNN.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github","colab_type":"text"},"source":["<a href=\"https://colab.research.google.com/github/sagihaider/CE888_2020/blob/master/Lab_7/Exercise2_DogvsCat_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"qTh9DiKVslsJ","colab_type":"text"},"source":["## Dogs vs. Cats \n","\n","In this competition, you'll write an algorithm to classify whether images contain either a dog or a cat.  This is easy for humans, dogs, and cats. Your computer will find it a bit more difficult.\n","\n","![alt text](https://miro.medium.com/max/3000/1*bhFifratH9DjKqMBTeQG5A.gif)\n","\n","Ref: https://medium.com/@thegrigorian/rolling-in-the-deep-cnn-c8d3f7108c8c"]},{"cell_type":"code","metadata":{"id":"YmXSOc0tZIGA","colab_type":"code","outputId":"d11853bd-5b88-4675-86a5-2de9fb6548f7","executionInfo":{"status":"ok","timestamp":1582732615030,"user_tz":0,"elapsed":6295,"user":{"displayName":"Eduardo De La Garza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBIc3o0vj7qsWySObh6eIWy5blAe5BDCXNiSB2x=s64","userId":"07738091253963309901"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["import os\n","os.environ['KAGGLE_USERNAME'] = \"eduardodelagarza\" # username from the json file\n","os.environ['KAGGLE_KEY'] = \"2727aa29984e714e5166a2be70edc26a\" # key from the json file\n","!kaggle competitions download -c dogs-vs-cats # api copied from kaggle"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n","test1.zip: Skipping, found more recently modified local copy (use --force to force download)\n","sampleSubmission.csv: Skipping, found more recently modified local copy (use --force to force download)\n","train.zip: Skipping, found more recently modified local copy (use --force to force download)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PiwIL8d1n7eS","colab_type":"code","outputId":"67026978-a3b2-49dd-9d95-4bce869fee6c","executionInfo":{"status":"ok","timestamp":1582732627951,"user_tz":0,"elapsed":18654,"user":{"displayName":"Eduardo De La Garza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBIc3o0vj7qsWySObh6eIWy5blAe5BDCXNiSB2x=s64","userId":"07738091253963309901"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["# Upload data\n","from zipfile import ZipFile\n","\n","file_name = \"/content/train.zip\"\n","\n","with ZipFile(file_name, 'r') as zip:\n","  zip.extractall()\n","  print('done')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["done\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sa2Bj5i7pPKV","colab_type":"code","outputId":"0a912c95-6a88-4fab-9cc5-237bf57d4545","executionInfo":{"status":"ok","timestamp":1582732627953,"user_tz":0,"elapsed":10623,"user":{"displayName":"Eduardo De La Garza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBIc3o0vj7qsWySObh6eIWy5blAe5BDCXNiSB2x=s64","userId":"07738091253963309901"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["data_dir_list = os.listdir('/content/train')\n","#print(data_dir_list)\n","\n","path, dirs, files = next(os.walk(\"/content/train\"))\n","file_count = len(files)\n","print(file_count)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["25000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0ERlHkfHqpK8","colab_type":"code","colab":{}},"source":["original_dataset_dir = '/content/train'\n","base_dir = '/content/cats_and_dogs_small'\n","os.mkdir(base_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AANB1UJ6rQhM","colab_type":"code","outputId":"bcf29384-5ca5-4af2-ad2b-5b46bdab51d9","executionInfo":{"status":"error","timestamp":1582732720113,"user_tz":0,"elapsed":767,"user":{"displayName":"Eduardo De La Garza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBIc3o0vj7qsWySObh6eIWy5blAe5BDCXNiSB2x=s64","userId":"07738091253963309901"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["train_dir = os.path.join(base_dir, 'train')\n","os.mkdir(train_dir)\n","\n","validation_dir = os.path.join(base_dir, 'validation')\n","os.mkdir(validation_dir)\n","\n","test_dir = os.path.join(base_dir, 'test')\n","os.mkdir(test_dir)\n","\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","os.mkdir(train_cats_dir)\n","\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","os.mkdir(train_dogs_dir)\n","\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","os.mkdir(validation_cats_dir)\n","\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n","os.mkdir(validation_dogs_dir)\n","\n","test_cats_dir = os.path.join(test_dir, 'cats')\n","os.mkdir(test_cats_dir)\n","\n","test_dogs_dir = os.path.join(test_dir, 'dogs')\n","os.mkdir(test_dogs_dir)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"FileExistsError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-61bb048c1097>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrain_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvalidation_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/cats_and_dogs_small/train'"]}]},{"cell_type":"code","metadata":{"id":"ULRgL9s9rV8T","colab_type":"code","outputId":"1c94ad90-86c0-4c41-f794-0a1bd6b776ee","executionInfo":{"status":"error","timestamp":1582732647302,"user_tz":0,"elapsed":1106,"user":{"displayName":"Eduardo De La Garza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBIc3o0vj7qsWySObh6eIWy5blAe5BDCXNiSB2x=s64","userId":"07738091253963309901"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["import shutil\n","fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(train_cats_dir, fname)\n","    #print(src,dst)\n","    shutil.copyfile(src, dst)\n","    \n","fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(validation_cats_dir, fname)\n","    shutil.copyfile(src, dst)\n","\n","fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(test_cats_dir, fname)\n","    shutil.copyfile(src, dst)\n","    \n","fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(train_dogs_dir, fname)\n","    shutil.copyfile(src, dst)\n","\n","fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(validation_dogs_dir, fname)\n","    shutil.copyfile(src, dst)\n","\n","fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(test_dogs_dir, fname)\n","    shutil.copyfile(src, dst)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-e39ef3059551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_dataset_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cats_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;31m#print(src,dst)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_cats_dir' is not defined"]}]},{"cell_type":"code","metadata":{"id":"ul3XAbIyr7vC","colab_type":"code","outputId":"0b87345d-4ad0-4abb-c3cc-4b70ba84abee","executionInfo":{"status":"error","timestamp":1582732647943,"user_tz":0,"elapsed":1107,"user":{"displayName":"Eduardo De La Garza","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mBIc3o0vj7qsWySObh6eIWy5blAe5BDCXNiSB2x=s64","userId":"07738091253963309901"}},"colab":{"base_uri":"https://localhost:8080/","height":232}},"source":["print('total training cat images:', len(os.listdir(train_cats_dir)))\n","print('total training dog images:', len(os.listdir(train_dogs_dir)))\n","print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n","\n","print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n","print('total test cat images:', len(os.listdir(test_cats_dir)))\n","print('total test dog images:', len(os.listdir(test_dogs_dir)))"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-fcb0f1072831>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total training cat images:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cats_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total training dog images:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dogs_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total validation cat images:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_cats_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total validation dog images:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dogs_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_cats_dir' is not defined"]}]},{"cell_type":"code","metadata":{"id":"o9yTA21_r-ma","colab_type":"code","colab":{}},"source":["from keras import layers\n","from keras import models\n","\n","model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2mG8wekxsBVS","colab_type":"code","colab":{}},"source":["from keras import optimizers\n","model.compile(loss='binary_crossentropy', \n","              optimizer=optimizers.RMSprop(lr=1e-4),\n","              metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7zS4Klm8qWp6","colab_type":"text"},"source":["## Using ImageDataGenerator to read images from directories\n","As you know by now, data should be formatted into appropriately preprocessed floatingpoint tensors before being fed into the network. Currently, the data sits on a drive as JPEG files, so the steps for getting it into the network are roughly as follows:\n","\n","* Read the picture files.\n","* Decode the JPEG content to RGB grids of pixels.\n","* Convert these into floating-point tensors.\n","* Rescale the pixel values (between 0 and 255) to the [0, 1] interval (as you know, neural networks prefer to deal with small input values).\n","\n","It may seem a bit daunting, but fortunately Keras has utilities to take care of these steps automatically. Keras has a module with image-processing helper tools, located at keras.preprocessing.image. In particular, it contains the class ImageDataGenerator,which lets you quickly set up Python generators that can automatically turn image files on disk into batches of preprocessed tensors."]},{"cell_type":"code","metadata":{"id":"XJ7XU7t9sEh6","colab_type":"code","colab":{}},"source":["from keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    target_size=(150, 150), \n","                                                    batch_size=20,\n","                                                    class_mode='binary')\n","\n","validation_generator = test_datagen.flow_from_directory(validation_dir,\n","                                                        target_size=(150, 150),\n","                                                        batch_size=20,\n","                                                        class_mode='binary')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SEgLywySqm4u","colab_type":"text"},"source":["Let’s fit the model to the data using the generator. You do so using the fit_generator method, the equivalent of fit for data generators like this one. It expects as its first argument a Python generator that will yield batches of inputs and targets indefinitely,like this one does. Because the data is being generated endlessly, the Keras model needs to know how many samples to draw from the generator before declaring anepoch over. This is the role of the `steps_per_epoch` argument: after having drawn `steps_per_epoch` batches from the generator—that is, after having run for `steps_per_epoch` gradient descent steps—the fitting process will go to the next epoch. In this case, batches are 20 samples, so it will take 100 batches until you see your target of 2,000 samples.\n","\n","When using fit_generator, you can pass a validation_data argument, much as with the fit method. It’s important to note that this argument is allowed to be a data generator, but it could also be a tuple of Numpy arrays. If you pass a generator as validation_data, then this generator is expected to yield batches of validation data endlessly; thus you should also specify the validation_steps argument, which tells the process how many batches to draw from the validation generator for evaluation."]},{"cell_type":"code","metadata":{"id":"yMyfPphJsJG6","colab_type":"code","colab":{}},"source":["history = model.fit_generator(train_generator,\n","                              steps_per_epoch=100,\n","                              epochs=30,\n","                              validation_data=validation_generator,\n","                              validation_steps=10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MZaZ2HWZsNUi","colab_type":"code","colab":{}},"source":["model.save('cats_and_dogs_small_1.h5')\n","\n","import matplotlib.pyplot as plt\n","\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XKZmXmBcq_8-","colab_type":"text"},"source":["## Convolutional Networks with Dropout\n","\n","![alt text](https://camo.githubusercontent.com/ee6fa1073247cd2c3d241300caf110d7a7541bc5/68747470733a2f2f63646e2d696d616765732d312e6d656469756d2e636f6d2f6d61782f3830302f312a4972644a355067684439596f4f7956415137334d4a772e676966)\n","\n","Ref: https://github.com/mneha4/Training-Neural-Nets---Guidelines"]},{"cell_type":"code","metadata":{"id":"wu3cqeYQrDeN","colab_type":"code","colab":{}},"source":["model = models.Sequential()\n","model.add(layers.Conv2D(32, (3, 3), activation='relu',\n","input_shape=(150, 150, 3)))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n","model.add(layers.MaxPooling2D((2, 2)))\n","model.add(layers.Flatten())\n","model.add(layers.Dropout(0.5))\n","model.add(layers.Dense(512, activation='relu'))\n","model.add(layers.Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizers.RMSprop(lr=1e-4),\n","              metrics=['acc'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QSeLpvY0rH7F","colab_type":"code","colab":{}},"source":["\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   rotation_range=40,\n","                                   width_shift_range=0.2,\n","                                   height_shift_range=0.2,\n","                                   shear_range=0.2,\n","                                   zoom_range=0.2,\n","                                   horizontal_flip=True,)\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    target_size=(150, 150),\n","                                                    batch_size=32,\n","                                                    class_mode='binary')\n","\n","validation_generator = test_datagen.flow_from_directory(validation_dir,\n","                                                        target_size=(150, 150),\n","                                                        batch_size=32,\n","                                                        class_mode='binary')\n","\n","history = model.fit_generator(train_generator,\n","                              steps_per_epoch=100,\n","                              epochs=20,\n","                              validation_data=validation_generator,\n","                              validation_steps=50)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pVPGP_d1JfNk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}